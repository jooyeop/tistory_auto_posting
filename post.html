<h3 data-ke-size='size23'><b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>Lila: A Unified Benchmark for Mathematical Reasoning</span></b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'></span></h3><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>
 Mathematical reasoning skills are essential for general-purpose intelligent
systems to perform tasks from grocery shopping to climate modeling. Towards
evaluating and improving AI systems in this domain, we propose LILA, a unified
mathematical reasoning benchmark consisting of 23 diverse tasks along four
dimensions: (i) mathematical abilities e.g., arithmetic, calculus (ii) language
format e.g., question-answering, fill-in-the-blanks (iii) language diversity
e.g., no language, simple language (iv) external knowledge e.g., commonsense,
physics. We construct our benchmark by extending 20 datasets benchmark by
collecting task instructions and solutions in the form of Python programs,
thereby obtaining explainable solutions in addition to the correct answer. We
additionally introduce two evaluation datasets to measure out-of-distribution
performance and robustness to language perturbation. Finally, we introduce
BHASKARA, a general-purpose mathematical reasoning model trained on LILA.
Importantly, we find that multi-tasking leads to significant improvements
(average relative improvement of 21.83% F1 score vs. single-task models), while
the best performing model only obtains 60.40%, indicating the room for
improvement in general mathematical reasoning and understanding.

    </span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>수학적 추론 기술은 범용 지능을 위해 필수적이다.
식료품 쇼핑에서 기후 모델링에 이르기까지 작업을 수행하는 시스템. 방면
이 영역의 AI 시스템을 평가하고 개선하며, 우리는 통일된 LILA를 제안한다.
네 가지 작업을 따라 23개의 다양한 작업으로 구성된 수학적 추론 벤치마크
치수: (i) 수학 능력(예: 산술, 미적분(ii) 언어)
형식(예: 질문 작성, 질문 작성(iii) 언어 다양성)
예: 언어 없음, 간단한 언어(iv) 외부 지식(예: 상식,
물리학의 다음과 같이 20개의 데이터셋 벤치마크를 확장하여 벤치마크를 구성합니다.
Python 프로그램 형태로 작업 지침 및 솔루션을 수집합니다.
이에 따라 정답과 더불어 설명 가능한 해결책을 얻습니다. 우리가
또한 두 개의 평가 데이터 세트를 도입하여 분포 외 측정
언어 섭동에 대한 성능 및 견고성. 마지막으로 소개하겠습니다.
라일라에 대해 훈련된 범용 수학적 추론 모델인 BHASKARA.
중요한 것은 멀티태스킹이 상당한 개선으로 이어진다는 것입니다.
(단일 작업 모델에 비해 평균 21.83% F1 점수의 상대적 개선).
최고 성능 모델은 60.40%만 획득할 수 있으며, 이는 다음을 위한 여지를 나타낸다.
일반적인 수학적 추론과 이해의 향상&nbsp;</span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'>&nbsp;</p><h3 data-ke-size='size23'><b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>Do Charge Prediction Models Learn Legal Theory?</span></b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'></span></h3><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>
 The charge prediction task aims to predict the charge for a case given its
fact description. Recent models have already achieved impressive accuracy in
this task, however, little is understood about the mechanisms they use to
perform the judgment.For practical applications, a charge prediction model
should conform to the certain legal theory in civil law countries, as under the
framework of civil law, all cases are judged according to certain local legal
theories. In China, for example, nearly all criminal judges make decisions
based on the Four Elements Theory (FET).In this paper, we argue that
trustworthy charge prediction models should take legal theories into
consideration, and standing on prior studies in model interpretation, we
propose three principles for trustworthy models should follow in this task,
which are sensitive, selective, and presumption of innocence.We further design
a new framework to evaluate whether existing charge prediction models learn
legal theories. Our findings indicate that, while existing charge prediction
models meet the selective principle on a benchmark dataset, most of them are
still not sensitive enough and do not satisfy the presumption of innocence. Our
code and dataset are released at this https URL.

    </span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>요금 예측 작업은 주어진 경우에 대한 요금을 예측하는 것을 목표로 한다.
사실 묘사 최근 모델은 이미 다음과 같은 놀라운 정확도를 달성했습니다.
그러나 이 작업은 그들이 사용하는 메커니즘에 대해 거의 이해되지 않는다.
판결을 집행하다실제 적용의 경우 전하 예측 모델
민법 국가에서 특정 법률 이론에 부합해야 한다.
민법의 틀, 모든 사건은 특정 지역 법에 따라 판단된다.
이론들. 예를 들어, 중국에서는 거의 모든 형사 판사들이 결정을 내린다.
FET(Four Elements Theory)를 기반으로 합니다.이 논문에서, 우리는 다음과 같이 주장한다.
신뢰할 수 있는 요금 예측 모델은 법률 이론을 도입해야 한다.
고려 사항, 그리고 모델 해석의 선행 연구에 서서, 우리는.
신뢰할 수 있는 모델을 위한 세 가지 원칙을 이 작업에서 따라야 한다고 제안합니다.
민감하고, 선별적이고, 무죄 추정입니다.우리는 더욱 설계한다.
기존 요금 예측 모델이 학습하는지 여부를 평가하는 새로운 프레임워크
법률 이론 우리의 연구 결과는 기존의 전하 예측과 달리
모델은 벤치마크 데이터 세트에서 선택적 원칙을 충족하며, 대부분은
여전히 충분히 민감하지 않고 무죄 추정에 부합하지 않는다. 우리들의
코드 및 데이터 집합은 이 https URL에서 릴리스됩니다.&nbsp;</span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'>&nbsp;</p><h3 data-ke-size='size23'><b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>1Cademy @ Causal News Corpus 2022: Enhance Causal Span Detection via Beam-Search-based Position Selector</span></b><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'></span></h3><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>
 In this paper, we present our approach and empirical observations for
Cause-Effect Signal Span Detection -- Subtask 2 of Shared task
3~\cite{tan-etal-2022-event} at CASE 2022. The shared task aims to extract the
cause, effect, and signal spans from a given causal sentence. We model the task
as a reading comprehension (RC) problem and apply a token-level RC-based span
prediction paradigm to the task as the baseline. We explore different training
objectives to fine-tune the model, as well as data augmentation (DA) tricks
based on the language model (LM) for performance improvement. Additionally, we
propose an efficient beam-search post-processing strategy to due with the
drawbacks of span detection to obtain a further performance gain. Our approach
achieves an average $F_1$ score of 54.15 and ranks \textbf{$1^{st}$} in the
CASE competition. Our code is available at
\url{this https URL}.

    </span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'><span style='font-family: 'Noto Sans Demilight', 'Noto Sans KR';'>이 논문에서, 우리는 우리의 접근법과 경험적 관찰을 제시한다.
Cause-Effect Signal Span Detection -- Shared(공유) 작업의 하위 작업 2
CASE 2022에서 3~\cite{tan-et al-2022-event}. 공유 작업은 다음을 추출하는 것을 목표로 합니다.
주어진 인과적 문장의 원인, 효과 및 신호 범위. 작업을 모델링합니다.
독해력(RC) 문제로 토큰 레벨 RC 기반 스팬 적용
예측 패러다임을 기준으로 작업에 적용합니다. 우리는 서로 다른 교육을 탐구한다.
데이터 확대(DA) 요령뿐만 아니라 모델을 미세 조정하는 목표
언어 모델(LM)을 기반으로 성능 향상을 도모합니다. 추가적으로, 우리는
효율적인 빔 검색 후 처리 전략을 제안합니다.
추가적인 성능 향상을 위한 스팬 검출의 단점. 우리의 접근법
평균 $F_1$ 점수 54.15를 달성하고 \textbf{$1^{st}$를 순위 매긴다.
CASE 경쟁. 코드는 다음 위치에서 사용할 수 있습니다.
\url{this https URL}입니다.&nbsp;</span></p><p data-ke-size='size18'>&nbsp;</p><p data-ke-size='size18'>&nbsp;</p>